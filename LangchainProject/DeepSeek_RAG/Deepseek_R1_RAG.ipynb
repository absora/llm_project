{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PDFPlumberLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "file = \"DeepSeek_R1.pdf\"\n",
    "\n",
    "loader = PDFPlumberLoader(file)\n",
    "docs = loader.load()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=0)\n",
    "all_splits = text_splitter.split_documents(docs)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-24T15:43:52.973369Z",
     "start_time": "2025-03-24T15:43:51.765672Z"
    }
   },
   "id": "86246153162ddf04"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "\n",
    "local_embeddings = OllamaEmbeddings(model=\"nomic-embed-text\")\n",
    "vectorstore = Chroma.from_documents(documents=all_splits, embedding=local_embeddings)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-24T15:44:58.697541Z",
     "start_time": "2025-03-24T15:44:51.780093Z"
    }
   },
   "id": "a500ee593c70910a"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "engineeringtasks. Asaresult,DeepSeek-R1hasnotdemonstratedahugeimprovement\n",
      "over DeepSeek-V3 on software engineering benchmarks. Future versions will address\n",
      "thisbyimplementingrejectionsamplingonsoftwareengineeringdataorincorporating\n",
      "asynchronousevaluationsduringtheRLprocesstoimproveefficiency.\n",
      "16\n",
      "DeepSeek-R1avoidsintroducinglengthbiasduringGPT-basedevaluations,furthersolidifying\n",
      "itsrobustnessacrossmultipletasks.\n",
      "On math tasks, DeepSeek-R1 demonstrates performance on par with OpenAI-o1-1217,\n",
      "surpassingothermodelsbyalargemargin. Asimilartrendisobservedoncodingalgorithm\n",
      "tasks,suchasLiveCodeBenchandCodeforces,wherereasoning-focusedmodelsdominatethese\n",
      "benchmarks. Onengineering-orientedcodingtasks,OpenAI-o1-1217outperformsDeepSeek-R1\n",
      "first open research to validate that reasoning capabilities of LLMs can be incentivized\n",
      "purelythroughRL,withouttheneedforSFT.Thisbreakthroughpavesthewayforfuture\n",
      "advancementsinthisarea.\n",
      "• We introduce our pipeline to develop DeepSeek-R1. The pipeline incorporates two RL\n",
      "stagesaimedatdiscoveringimprovedreasoningpatternsandaligningwithhumanpref-\n",
      "erences, as well as two SFT stages that serve as the seed for the model’s reasoning and\n",
      "DeepSeek-R1,whichincorporatesasmallamountofcold-startdataandamulti-stagetraining\n",
      "pipeline. Specifically, we begin by collecting thousands of cold-start data to fine-tune the\n",
      "DeepSeek-V3-Basemodel. Followingthis,weperformreasoning-orientedRLlikeDeepSeek-R1-\n",
      "Zero. UponnearingconvergenceintheRLprocess,wecreatenewSFTdatathroughrejection\n",
      "samplingontheRLcheckpoint,combinedwithsuperviseddatafromDeepSeek-V3indomains\n",
      "suchaswriting,factualQA,andself-cognition,andthenretraintheDeepSeek-V3-Basemodel.\n"
     ]
    }
   ],
   "source": [
    "question = \"What is the purpose of the DeepSeek project?\"\n",
    "docs = vectorstore.similarity_search(question)\n",
    "\n",
    "for doc in docs:\n",
    "    print(doc.page_content)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-24T15:46:06.017809Z",
     "start_time": "2025-03-24T15:46:05.950743Z"
    }
   },
   "id": "cea98f884699a3fe"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "\"<think>\\nOkay, so the user wants me to summarize the main themes from the retrieved documents about DeepSeek-R1. Let me read through what they provided.\\n\\nFirst, there's a mention that DeepSeek-R1 hasn't improved as much on software engineering benchmarks compared to DeepSeek-V3. This is interesting because it suggests potential areas for improvement in its AI capabilities, especially in technical fields. The result is that future versions will focus on rejectionsampling of software engineering data or incorporating asynchronous evaluations during RL processes. That sounds like a strategic move to make the model more efficient.\\n\\nAnother point is about avoiding length bias in GPT evaluations and solidifying robustness across multiple tasks. This probably means that DeepSeek-R1 is versatile, handling various types of AI tasks well without favoriting longer responses too much.\\n\\nThen there's an observation on math and coding algorithm tasks, where models like OpenAI-o1-1217 outperform DeepSeek-R1. This could indicate areas where DeepSeek-R1 needs improvement or show potential if other models get better at those specific types of problems.\\n\\nThe user also notes that they've introduced a pipeline to develop DeepSeek-R1 and mentioned the introduction of SFT stages, which serve as seeds for reasoning using RL with cold-start data and multi-stage training. This suggests that the model is still in early stages but shows promise in certain areas. They plan to add rejection sampling on RL checkpoints combined with data from other domains like writing or factual QA, followed by retraining.\\n\\nPutting this together, the main themes seem to revolve around: improving efficiency through rejectionsampling, addressing technical AI gaps, leveraging multiple tasks for versatile performance, and refining reasoning in specific domains with ongoing work in integration. I should structure these points cohesively without getting too detailed on each point.\\n</think>\\n\\nThe main themes identified from the retrieved documents are:\\n\\n1. **Software Engineering Benchmark Improvements**: DeepSeek-R1 has shown limited progress over its predecessor, DeepSeek-V3, on software engineering benchmarks. Future versions will focus on implementing rejectionsampling techniques for such data or incorporating asynchronous evaluations during RL processes to improve efficiency.\\n\\n2. **Reasoning Capabilities Across AI Domains**: The model demonstrates strong performance in reasoning-focused tasks like math and coding algorithm benchmarks (e.g., LiveCodeBench, Codeforces) but lags behind models like OpenAI-o1-1217 on these types of problems. This suggests areas where DeepSeek-R1 may need improvement or potential for expansion.\\n\\n3. **Integration with Multi-Task Training**: The pipeline introduced aims to develop DeepSeek-R1 by combining cold-start data fine-tuning with multi-stage training, focusing on discovering improved reasoning patterns and aligning them with human preferences. This approach shows promise in versatility across different AI tasks but highlights areas for further optimization.\\n\\n4. **Rejection Sampling in RL Processes**: Future versions may incorporate rejectionsampling on RL checkpoints combined with supervised learning from other domains (e.g., writing, factual QA) to enhance efficiency and performance.\\n\\nOverall, the documents emphasize DeepSeek-R1's potential for addressing technical AI challenges through strategic improvements in reasoning and data integration.\""
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "model = ChatOllama(\n",
    "    model=\"deepseek-r1:1.5b\",\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"Summarize the main themes in these retrieved docs: {docs}\"\n",
    ")\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "chain = {\"docs\": format_docs} | prompt | model | StrOutputParser()\n",
    "question = \"What is the purpose of the DeepSeek project?\"\n",
    "docs = vectorstore.similarity_search(question)\n",
    "chain.invoke(docs)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-24T15:50:07.660665Z",
     "start_time": "2025-03-24T15:49:34.079385Z"
    }
   },
   "id": "bd5421fd058402f2"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "\"<think>\\nOkay, so I need to figure out the purpose of the DeepSeek project based on the provided context. Let me read through it carefully.\\n\\nThe context mentions that DeepSeek-R1 has demonstrated improvements over DeepSeek-V3 on software engineering benchmarks and future versions will include rejections sampling or asynchronous evaluations. It also talks about a pipeline for developing DeepSeek-R1, which uses two RL stages: one for discovering improved reasoning patterns aligned with human preferences and another as seed data. Then, the project starts by collecting thousands of cold-start data to fine-tune V3-Basemodel, followed by RL-like Zero, and then creates new SFT data using rejection sampling on RL checkpoints combined with supervised data from V3.\\n\\nHmm, it seems like DeepSeek-R1 is developed through a pipeline that includes both reinforcement learning (RL) stages and some form of data generation. The main focus seems to be on improving performance in software engineering tasks, which suggests their primary purpose might be in addressing this specific domain. Additionally, they mention future versions aiming to improve efficiency with rejections sampling or asynchronous evaluations, indicating ongoing development goals.\\n\\nPutting it all together, the project's purpose appears to be advancing AI systems' abilities in software engineering and other related areas through enhanced RL and data generation techniques.\\n</think>\\n\\nThe purpose of DeepSeek-R1 is to advance artificial intelligence systems, particularly in software engineering, by improving their performance through reinforcement learning (RL) and data generation. Future versions aim to enhance efficiency with rejections sampling or asynchronous evaluations, indicating ongoing development focused on this domain.\""
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "RAG_TEMPLATE = \"\"\"\n",
    "You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\n",
    "\n",
    "<context>\n",
    "{context}\n",
    "</context>\n",
    "\n",
    "Answer the following question:\n",
    "\n",
    "{question}\"\"\"\n",
    "\n",
    "rag_prompt = ChatPromptTemplate.from_template(RAG_TEMPLATE)\n",
    "\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "qa_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | rag_prompt\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "question = \"What is the purpose of the DeepSeek project?\"\n",
    "\n",
    "qa_chain.invoke(question)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-24T15:52:12.588148Z",
     "start_time": "2025-03-24T15:52:01.521017Z"
    }
   },
   "id": "33dcc3ea92bd23f5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "7e8e14931b201f71"
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "llm",
   "language": "python",
   "display_name": "llm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
